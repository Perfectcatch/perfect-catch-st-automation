# BATCH 9.5 - PART 4: WINDSURF DEPLOYMENT PROMPT

## Complete Deployment Guide

Copy and paste this entire prompt into Windsurf:

---

# ðŸš€ WINDSURF DEPLOYMENT - BATCH 9.5: COMPLETE DATA SYNC OVERHAUL

## CRITICAL CONTEXT

**Problem:** Current sync only stores IDs. All customer/job/estimate data is EMPTY.
**Solution:** Complete rewrite with enrichment pipeline that makes detail API calls.
**Impact:** Without this fix, nothing else works. This is the foundation.

**Repository:** `/opt/perfectcatch-st-automation` or `/opt/docker/servicetitan-ai/perfect-catch-st-automation`

---

## PHASE 1: APPLY DATABASE MIGRATION (5 minutes)

### 1.1 Create Migration File

Create `src/db/migrations/007_sync_enrichment.sql` with complete migration from Part 3.

### 1.2 Apply Migration

```bash
cd /opt/perfectcatch-st-automation

PGPASSWORD='Catchadmin@2025' psql \
  -h localhost \
  -p 6432 \
  -U postgres \
  -d perfectcatch_automation \
  -f src/db/migrations/007_sync_enrichment.sql
```

### 1.3 Verify Migration

```sql
-- Check new columns exist
SELECT column_name 
FROM information_schema.columns 
WHERE table_name = 'st_customers' 
AND column_name IN ('total_jobs', 'lifetime_value', 'last_synced_at');

-- Should return 3 rows
```

---

## PHASE 2: CREATE SYNC BASE CLASS (10 minutes)

### 2.1 Update ServiceTitan Client

Replace `src/lib/servicetitan-client.js` with enhanced version from Part 1.

Key additions:
- `fetchAllPages()` - Auto-pagination
- `fetchDetailsBatch()` - Parallel detail fetching with rate limiting
- Better error handling and retries

### 2.2 Create Sync Base Class

Create `src/services/sync/sync-base.js` from Part 1.

This provides:
- Standard sync workflow (fetch â†’ enrich â†’ transform â†’ upsert)
- Progress logging
- Error handling
- Sync log recording

---

## PHASE 3: REPLACE SYNC MODULES (30 minutes)

### 3.1 Backup Existing Syncs

```bash
cd /opt/perfectcatch-st-automation/src/services/sync

# Create backup
mkdir -p backup_$(date +%Y%m%d)
cp sync-*.js backup_$(date +%Y%m%d)/
```

### 3.2 Replace Each Sync Module

Replace these files with versions from Parts 1-3:

1. **sync-customers.js** (Part 1)
   - Fetches customer list
   - Enriches with full details via `/customers/{id}`
   - Fetches location via `/locations/{id}`
   - Extracts email/phone from various fields
   - Calculates aggregates

2. **sync-jobs.js** (Part 2)
   - Fetches job list
   - Enriches with full details
   - Gets job history and appointments
   - Updates business unit stats

3. **sync-estimates.js** (Part 2)
   - Fetches estimate list
   - Enriches with line items
   - Calculates conversion metrics

4. **sync-invoices.js** (Part 2)
   - Fetches invoice list
   - Enriches with items and payments
   - Calculates AR aging
   - Syncs payments to separate table

5. **sync-appointments.js** (Part 3)
   - Tries multiple API endpoints
   - Falls back to job appointments if needed
   - Tracks arrival/departure times

6. **sync-technicians.js** (Part 3)
   - Fetches from both technicians and employees endpoints
   - Combines and deduplicates
   - Calculates performance metrics

7. **sync-reference-data.js** (Part 3)
   - Business units
   - Job types
   - Campaigns
   - Tag types

8. **sync-orchestrator.js** (Part 3)
   - Coordinates all syncs
   - Proper ordering (reference â†’ customers â†’ jobs â†’ etc.)
   - Refreshes aggregates at end

---

## PHASE 4: UPDATE PACKAGE.JSON (5 minutes)

Add these scripts to `package.json`:

```json
{
  "scripts": {
    "sync:full": "node -e \"import('./src/services/sync/sync-orchestrator.js').then(m => m.runFullSync())\"",
    "sync:customers": "node -e \"import('./src/services/sync/sync-customers.js').then(m => m.syncCustomers())\"",
    "sync:jobs": "node -e \"import('./src/services/sync/sync-jobs.js').then(m => m.syncJobs())\"",
    "sync:estimates": "node -e \"import('./src/services/sync/sync-estimates.js').then(m => m.syncEstimates())\"",
    "sync:invoices": "node -e \"import('./src/services/sync/sync-invoices.js').then(m => m.syncInvoices())\"",
    "sync:appointments": "node -e \"import('./src/services/sync/sync-appointments.js').then(m => m.syncAppointments())\"",
    "sync:technicians": "node -e \"import('./src/services/sync/sync-technicians.js').then(m => m.syncTechnicians())\"",
    "sync:reference": "node -e \"import('./src/services/sync/sync-reference-data.js').then(m => m.syncReferenceData())\"",
    "sync:aggregates": "node -e \"import('./src/services/sync/sync-base.js').then(m => m.prisma.$executeRaw\\`SELECT refresh_all_aggregates()\\`)\""
  }
}
```

---

## PHASE 5: RUN COMPLETE SYNC (30-60 minutes)

### 5.1 Run Full Sync

```bash
cd /opt/perfectcatch-st-automation

# Set environment (if not already)
export DATABASE_URL="postgresql://postgres:Catchadmin@2025@localhost:6432/perfectcatch_automation"
export SERVICE_TITAN_CLIENT_ID="your_client_id"
export SERVICE_TITAN_CLIENT_SECRET="your_client_secret"
export SERVICE_TITAN_TENANT_ID="your_tenant_id"
export SERVICE_TITAN_APP_KEY="your_app_key"

# Run full sync
npm run sync:full
```

### 5.2 Watch Progress

The sync will output progress like:
```
[INFO] ============================================================
[INFO] STARTING FULL SYNC WITH ENRICHMENT
[INFO] ============================================================
[INFO] --- PHASE 0: Reference Data ---
[INFO] [reference] Syncing business units...
[INFO] [reference] Synced 6 business units
...
[INFO] --- PHASE 1: Customers ---
[INFO] [customers] Step 1: Fetching list...
[INFO] [customers] Fetched 1682 records
[INFO] [customers] Step 2: Enriching with details...
[INFO] [customers] Enriched 100/1682
[INFO] [customers] Enriched 200/1682
...
```

### 5.3 Expected Duration

- Customers: 5-15 minutes (depending on count)
- Jobs: 10-20 minutes
- Estimates: 5-10 minutes
- Invoices: 5-10 minutes
- Appointments: 2-5 minutes
- Technicians: 1-2 minutes

**Total: 30-60 minutes for initial sync**

---

## PHASE 6: VERIFY DATA (10 minutes)

### 6.1 Check Customer Data

```sql
-- Connect to database
PGPASSWORD='Catchadmin@2025' psql -h localhost -p 6432 -U postgres -d perfectcatch_automation

-- Check customers have data now
SELECT 
  st_id,
  name,
  email,
  phone,
  city,
  state,
  total_jobs,
  lifetime_value,
  last_synced_at
FROM st_customers
WHERE name IS NOT NULL AND name != ''
LIMIT 10;

-- Count enriched vs empty
SELECT 
  COUNT(*) as total,
  COUNT(*) FILTER (WHERE name IS NOT NULL AND name != '') as has_name,
  COUNT(*) FILTER (WHERE email IS NOT NULL) as has_email,
  COUNT(*) FILTER (WHERE phone IS NOT NULL) as has_phone,
  COUNT(*) FILTER (WHERE city IS NOT NULL) as has_address
FROM st_customers;
```

### 6.2 Check Jobs Data

```sql
SELECT 
  st_id,
  job_number,
  summary,
  job_status,
  technician_name,
  customer_id
FROM st_jobs
WHERE summary IS NOT NULL
ORDER BY st_created_on DESC
LIMIT 10;

-- Count by status
SELECT job_status, COUNT(*) 
FROM st_jobs 
GROUP BY job_status 
ORDER BY COUNT(*) DESC;
```

### 6.3 Check Estimates Data

```sql
SELECT 
  st_id,
  estimate_number,
  name,
  status,
  total,
  item_count
FROM st_estimates
WHERE total > 0
ORDER BY st_created_on DESC
LIMIT 10;

-- Conversion stats
SELECT 
  status,
  COUNT(*) as count,
  SUM(total) as total_value,
  AVG(total) as avg_value
FROM st_estimates
GROUP BY status;
```

### 6.4 Check Sync Status View

```sql
SELECT * FROM v_sync_status;

-- Should show counts for all entities
```

### 6.5 Check Complete Customer View

```sql
SELECT 
  st_id,
  name,
  email,
  phone,
  location_city,
  location_state,
  job_count,
  open_estimates,
  outstanding_balance
FROM v_customers_complete
WHERE lifetime_value > 0
ORDER BY lifetime_value DESC
LIMIT 10;
```

---

## PHASE 7: TROUBLESHOOTING

### Issue 1: "Connection refused" or "ECONNREFUSED"

```bash
# Check database is running
docker ps | grep postgres

# Check connection
psql -h localhost -p 6432 -U postgres -d perfectcatch_automation -c "SELECT 1"
```

### Issue 2: "401 Unauthorized" from ServiceTitan

```bash
# Check credentials
echo $SERVICE_TITAN_CLIENT_ID
echo $SERVICE_TITAN_CLIENT_SECRET
echo $SERVICE_TITAN_TENANT_ID

# Test token generation manually
curl -X POST https://auth.servicetitan.io/connect/token \
  -d "grant_type=client_credentials&client_id=$SERVICE_TITAN_CLIENT_ID&client_secret=$SERVICE_TITAN_CLIENT_SECRET"
```

### Issue 3: "Rate limited" (429 errors)

The sync includes rate limiting, but if you still hit limits:
- Reduce batch size in sync modules (change `batchSize` from 10 to 5)
- Increase sleep time between batches

### Issue 4: "Column does not exist"

```bash
# Migration may not have run - rerun it
PGPASSWORD='Catchadmin@2025' psql -h localhost -p 6432 -U postgres -d perfectcatch_automation \
  -f src/db/migrations/007_sync_enrichment.sql
```

### Issue 5: Still getting empty data

Check the ServiceTitan API response:
```javascript
// Add this logging to sync-customers.js enrichOne():
console.log('Raw API response:', JSON.stringify(details, null, 2));
```

The data might be in different fields than expected. Check the `full_data` column:
```sql
SELECT st_id, full_data FROM st_customers LIMIT 1;
```

---

## VERIFICATION CHECKLIST

After sync completes, verify:

- [ ] Customers have names (not empty strings)
- [ ] Customers have email OR phone
- [ ] Customers have addresses (city, state)
- [ ] Jobs have summaries
- [ ] Jobs have status values
- [ ] Estimates have totals > 0
- [ ] Estimates have item_count > 0
- [ ] Invoices have totals
- [ ] Technicians exist in table
- [ ] v_sync_status shows record counts
- [ ] v_customers_complete returns data

---

## SUCCESS CRITERIA

**BEFORE:**
```sql
SELECT COUNT(*) FROM st_customers WHERE name IS NOT NULL AND name != '';
-- Result: 0 or very few
```

**AFTER:**
```sql
SELECT COUNT(*) FROM st_customers WHERE name IS NOT NULL AND name != '';
-- Result: Should match total customer count (1600+)
```

---

## NEXT STEPS

After successful sync:

1. **Schedule recurring sync**
   - Add to cron or Docker worker
   - Run incremental every 6 hours
   - Run full sync daily at 2 AM

2. **Test MCP tools**
   - Now that data exists, MCP tools will work
   - Try: "Show me insights for customer ID 1"

3. **Continue to Batch 10**
   - Worker health fixes
   - GHL integration
   - Slack integration

---

## OUTPUT REQUIREMENTS

After deployment, provide:

1. **Migration Results**
   - Columns added
   - Indexes created
   - Views created

2. **Sync Results**
   - Records per entity
   - Duration
   - Any errors

3. **Data Verification**
   - Customer count with names
   - Customer count with emails
   - Job count
   - Estimate count
   - v_sync_status output

4. **Sample Data**
   - Top 5 customers by lifetime value
   - Recent jobs

---

## BEGIN DEPLOYMENT

Start with Phase 1 (Migration) and proceed through each phase.

This is the FOUNDATION - everything else depends on having real data!

**Estimated Time:** 2-3 hours (including sync run time)
